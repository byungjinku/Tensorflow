{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets, model_selection\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# from tensorflow.keras.backend import one_hot #session run이 필요하다. \n",
    "from tensorflow.keras.utils import to_categorical #session이 필요 없기 때문에 이걸 쓰면 된다. 굳이 one-hot으로 변경 안해도 된다.\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-3723595d4c6c>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)  # 0~9 있으니까 one-hot 인코팅으로 하면 =10이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = mnist.train.images\n",
    "x_test = mnist.test.images\n",
    "y_train = mnist.train.labels\n",
    "y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape #28*28 픽셀 이미지인데, 이걸 1차원 행으로 reshape 한 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.constant(y_train, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w1 = tf.get_variable('w1',[784,100], initializer=tf.contrib.layers.xavier_initializer()) #deep-learning #xavier 초기화 해줌\n",
    "b1 = tf.get_variable('b1',[100], initializer=tf.contrib.layers.xavier_initializer())\n",
    "z1 = tf.matmul(x,w1) + b1 #(784,100)\n",
    "lay1 = tf.nn.relu(z1)  #학습이 안되면 중간중간 RELu를 넣어주어야 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2 = tf.get_variable('w2',[100,10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.get_variable('b2',[10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "z2 = tf.matmul(lay1,w2) + b2 \n",
    "hx = tf.nn.softmax(z2) #맨 마지막에는 무조건 softmax가 와야한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_i = tf.nn.softmax_cross_entropy_with_logits_v2(logits=z2, labels=y)  #소프트맥스와 크로스앤트로피가 결합되어있는 것이다. \n",
    "\n",
    "cost = tf.reduce_mean(cost_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.1) #Learning rate\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.2887235\n",
      "1 2.1669064\n",
      "2 2.067996\n",
      "3 1.9818478\n",
      "4 1.9037384\n",
      "5 1.831106\n",
      "6 1.7625241\n",
      "7 1.6971983\n",
      "8 1.6348389\n",
      "9 1.575299\n",
      "10 1.5185043\n",
      "11 1.464388\n",
      "12 1.4129505\n",
      "13 1.3642235\n",
      "14 1.318163\n",
      "15 1.2747153\n",
      "16 1.2338067\n",
      "17 1.1953253\n",
      "18 1.1591661\n",
      "19 1.1252179\n",
      "20 1.0933603\n",
      "21 1.063477\n",
      "22 1.0354387\n",
      "23 1.0091072\n",
      "24 0.9843679\n",
      "25 0.96110874\n",
      "26 0.93923116\n",
      "27 0.9186282\n",
      "28 0.8992021\n",
      "29 0.8808639\n",
      "30 0.8635305\n",
      "31 0.84713423\n",
      "32 0.8316035\n",
      "33 0.816882\n",
      "34 0.8029118\n",
      "35 0.789639\n",
      "36 0.7770152\n",
      "37 0.76499474\n",
      "38 0.7535384\n",
      "39 0.7426094\n",
      "40 0.7321733\n",
      "41 0.72219616\n",
      "42 0.71264964\n",
      "43 0.7035098\n",
      "44 0.69475013\n",
      "45 0.68634737\n",
      "46 0.67827874\n",
      "47 0.670525\n",
      "48 0.6630688\n",
      "49 0.65589356\n",
      "50 0.6489858\n",
      "51 0.64232713\n",
      "52 0.6359052\n",
      "53 0.62970775\n",
      "54 0.6237219\n",
      "55 0.6179369\n",
      "56 0.6123436\n",
      "57 0.6069329\n",
      "58 0.6016957\n",
      "59 0.5966236\n",
      "60 0.5917087\n",
      "61 0.5869435\n",
      "62 0.5823221\n",
      "63 0.57783735\n",
      "64 0.5734839\n",
      "65 0.5692545\n",
      "66 0.5651435\n",
      "67 0.5611465\n",
      "68 0.5572591\n",
      "69 0.5534772\n",
      "70 0.5497959\n",
      "71 0.54621065\n",
      "72 0.5427182\n",
      "73 0.53931504\n",
      "74 0.5359981\n",
      "75 0.5327635\n",
      "76 0.5296076\n",
      "77 0.52652746\n",
      "78 0.5235209\n",
      "79 0.5205848\n",
      "80 0.5177169\n",
      "81 0.51491475\n",
      "82 0.51217586\n",
      "83 0.5094978\n",
      "84 0.5068792\n",
      "85 0.5043183\n",
      "86 0.5018121\n",
      "87 0.4993592\n",
      "88 0.4969576\n",
      "89 0.49460644\n",
      "90 0.49230412\n",
      "91 0.490049\n",
      "92 0.48783886\n",
      "93 0.4856726\n",
      "94 0.4835486\n",
      "95 0.4814659\n",
      "96 0.47942358\n",
      "97 0.47741988\n",
      "98 0.47545376\n",
      "99 0.47352412\n",
      "100 0.4716304\n",
      "101 0.46977112\n",
      "102 0.46794474\n",
      "103 0.46615088\n",
      "104 0.46438903\n",
      "105 0.46265846\n",
      "106 0.4609583\n",
      "107 0.45928714\n",
      "108 0.4576446\n",
      "109 0.45602947\n",
      "110 0.45444125\n",
      "111 0.45287898\n",
      "112 0.4513421\n",
      "113 0.4498299\n",
      "114 0.44834167\n",
      "115 0.44687653\n",
      "116 0.4454343\n",
      "117 0.44401464\n",
      "118 0.44261682\n",
      "119 0.4412404\n",
      "120 0.4398847\n",
      "121 0.43854934\n",
      "122 0.43723366\n",
      "123 0.4359375\n",
      "124 0.43466017\n",
      "125 0.43340117\n",
      "126 0.43216008\n",
      "127 0.4309363\n",
      "128 0.42972934\n",
      "129 0.42853916\n",
      "130 0.42736542\n",
      "131 0.42620787\n",
      "132 0.425066\n",
      "133 0.42393932\n",
      "134 0.42282748\n",
      "135 0.42173022\n",
      "136 0.42064682\n",
      "137 0.41957757\n",
      "138 0.41852173\n",
      "139 0.41747913\n",
      "140 0.41644967\n",
      "141 0.41543302\n",
      "142 0.41442895\n",
      "143 0.41343707\n",
      "144 0.41245726\n",
      "145 0.41148922\n",
      "146 0.4105327\n",
      "147 0.40958765\n",
      "148 0.40865383\n",
      "149 0.40773076\n",
      "150 0.40681824\n",
      "151 0.4059162\n",
      "152 0.4050244\n",
      "153 0.40414262\n",
      "154 0.40327075\n",
      "155 0.40240875\n",
      "156 0.40155607\n",
      "157 0.4007125\n",
      "158 0.3998782\n",
      "159 0.3990527\n",
      "160 0.398236\n",
      "161 0.39742774\n",
      "162 0.396628\n",
      "163 0.39583656\n",
      "164 0.3950532\n",
      "165 0.39427778\n",
      "166 0.39350995\n",
      "167 0.39274985\n",
      "168 0.39199722\n",
      "169 0.391252\n",
      "170 0.39051414\n",
      "171 0.38978338\n",
      "172 0.38905972\n",
      "173 0.38834304\n",
      "174 0.38763323\n",
      "175 0.38693032\n",
      "176 0.38623416\n",
      "177 0.38554427\n",
      "178 0.38486087\n",
      "179 0.3841837\n",
      "180 0.38351285\n",
      "181 0.38284796\n",
      "182 0.38218915\n",
      "183 0.38153625\n",
      "184 0.3808891\n",
      "185 0.38024774\n",
      "186 0.379612\n",
      "187 0.37898174\n",
      "188 0.37835678\n",
      "189 0.37773722\n",
      "190 0.3771229\n",
      "191 0.37651372\n",
      "192 0.37590963\n",
      "193 0.37531036\n",
      "194 0.37471613\n",
      "195 0.37412685\n",
      "196 0.37354204\n",
      "197 0.372962\n",
      "198 0.37238654\n",
      "199 0.37181574\n",
      "200 0.37124932\n",
      "201 0.37068737\n",
      "202 0.37012982\n",
      "203 0.36957657\n",
      "204 0.3690274\n",
      "205 0.36848232\n",
      "206 0.36794135\n",
      "207 0.3674046\n",
      "208 0.36687198\n",
      "209 0.36634326\n",
      "210 0.36581832\n",
      "211 0.36529738\n",
      "212 0.36478025\n",
      "213 0.36426684\n",
      "214 0.36375716\n",
      "215 0.36325127\n",
      "216 0.3627489\n",
      "217 0.36225003\n",
      "218 0.3617548\n",
      "219 0.36126292\n",
      "220 0.3607746\n",
      "221 0.3602895\n",
      "222 0.35980782\n",
      "223 0.35932928\n",
      "224 0.35885397\n",
      "225 0.3583819\n",
      "226 0.357913\n",
      "227 0.35744724\n",
      "228 0.35698438\n",
      "229 0.35652465\n",
      "230 0.35606784\n",
      "231 0.35561398\n",
      "232 0.35516322\n",
      "233 0.35471532\n",
      "234 0.3542703\n",
      "235 0.3538281\n",
      "236 0.3533887\n",
      "237 0.35295206\n",
      "238 0.35251817\n",
      "239 0.35208687\n",
      "240 0.35165817\n",
      "241 0.3512321\n",
      "242 0.35080874\n",
      "243 0.35038784\n",
      "244 0.34996945\n",
      "245 0.3495534\n",
      "246 0.3491398\n",
      "247 0.3487287\n",
      "248 0.34832016\n",
      "249 0.3479141\n",
      "250 0.34751043\n",
      "251 0.34710908\n",
      "252 0.3467101\n",
      "253 0.34631345\n",
      "254 0.3459191\n",
      "255 0.34552702\n",
      "256 0.34513715\n",
      "257 0.34474948\n",
      "258 0.34436402\n",
      "259 0.34398058\n",
      "260 0.34359935\n",
      "261 0.34322017\n",
      "262 0.34284317\n",
      "263 0.34246814\n",
      "264 0.34209496\n",
      "265 0.3417237\n",
      "266 0.34135452\n",
      "267 0.3409872\n",
      "268 0.34062183\n",
      "269 0.3402584\n",
      "270 0.33989677\n",
      "271 0.33953708\n",
      "272 0.33917925\n",
      "273 0.33882323\n",
      "274 0.33846912\n",
      "275 0.33811677\n",
      "276 0.33776617\n",
      "277 0.33741716\n",
      "278 0.33706984\n",
      "279 0.33672443\n",
      "280 0.33638093\n",
      "281 0.3360391\n",
      "282 0.33569905\n",
      "283 0.3353605\n",
      "284 0.33502364\n",
      "285 0.33468837\n",
      "286 0.33435458\n",
      "287 0.3340225\n",
      "288 0.33369198\n",
      "289 0.33336294\n",
      "290 0.33303544\n",
      "291 0.33270943\n",
      "292 0.33238497\n",
      "293 0.33206186\n",
      "294 0.33174032\n",
      "295 0.3314201\n",
      "296 0.3311012\n",
      "297 0.33078372\n",
      "298 0.3304676\n",
      "299 0.33015302\n"
     ]
    }
   ],
   "source": [
    "for i in range( 300):  #최대한 돌려주고 earlystopping 돌리면 된다. \n",
    "    sess.run( train, {x:x_train})\n",
    "    print( i, sess.run(cost, {x:x_train}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.32941177, 0.7254902 , 0.62352943, 0.5921569 ,\n",
       "        0.23529413, 0.14117648, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.8705883 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "        0.9960785 , 0.9450981 , 0.77647066, 0.77647066, 0.77647066,\n",
       "        0.77647066, 0.77647066, 0.77647066, 0.77647066, 0.77647066,\n",
       "        0.6666667 , 0.20392159, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.2627451 , 0.44705886, 0.28235295, 0.44705886,\n",
       "        0.6392157 , 0.89019614, 0.9960785 , 0.882353  , 0.9960785 ,\n",
       "        0.9960785 , 0.9960785 , 0.9803922 , 0.8980393 , 0.9960785 ,\n",
       "        0.9960785 , 0.54901963, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
       "        0.2627451 , 0.2627451 , 0.23137257, 0.08235294, 0.92549026,\n",
       "        0.9960785 , 0.4156863 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3254902 , 0.9921569 ,\n",
       "        0.8196079 , 0.07058824, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.08627451, 0.91372555, 1.        ,\n",
       "        0.3254902 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.5058824 , 0.9960785 , 0.9333334 ,\n",
       "        0.17254902, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.23137257, 0.97647065, 0.9960785 , 0.24313727,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.52156866, 0.9960785 , 0.73333335, 0.01960784,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.03529412, 0.80392164, 0.9725491 , 0.227451  , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.49411768, 0.9960785 , 0.7137255 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.29411766,\n",
       "        0.9843138 , 0.94117653, 0.22352943, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.07450981, 0.86666673,\n",
       "        0.9960785 , 0.6509804 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.7960785 , 0.9960785 ,\n",
       "        0.8588236 , 0.13725491, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.14901961, 0.9960785 , 0.9960785 ,\n",
       "        0.3019608 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.12156864, 0.87843144, 0.9960785 , 0.45098042,\n",
       "        0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.52156866, 0.9960785 , 0.9960785 , 0.20392159,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.2392157 , 0.9490197 , 0.9960785 , 0.9960785 , 0.20392159,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.47450984, 0.9960785 , 0.9960785 , 0.8588236 , 0.15686275,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.47450984, 0.9960785 , 0.8117648 , 0.07058824, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0].reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[0].reshape(28,28))\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.5818495e-04, 9.4068682e-06, 2.9692595e-04, 2.8528997e-03,\n",
       "        2.9379860e-05, 1.6098951e-04, 1.9529787e-06, 9.9102122e-01,\n",
       "        1.6677621e-04, 5.3021894e-03]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(hx, {x:x_test[[0]]}) #7이라는 이미지를 주었을 때 예측값이 얼마인가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(hx, {x:x_test[[0]]}).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = sess.run(hx,{x:x_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9138"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t.argmax(axis=1)==y_test.argmax(axis=1)).mean() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정확도를 더 높게하는 방법\n",
    "\n",
    ": 'cnn'을 활용하면 정확도가 100퍼센트 가까이 나온다. \n",
    "\n",
    "- 사람 얼굴이나 복잡한 이미지 training 할 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
