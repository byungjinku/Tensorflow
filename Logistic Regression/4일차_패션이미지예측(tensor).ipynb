{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets.fashion_mnist import load_data\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets, model_selection\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.keras.backend import one_hot #session run이 필요하다. \n",
    "from tensorflow.keras.utils import to_categorical #session이 필요 없기 때문에 이걸 쓰면 된다. 굳이 one-hot으로 변경 안해도 된다.\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images,train_labels),(test_images,test_labels) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (train_images,train_labels),(test_images,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images=train_images.reshape(60000,784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images=test_images.reshape(10000,784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_images\n",
    "x_test = test_images\n",
    "y_train = train_labels\n",
    "y_test = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "t= one_hot(train_labels,10)\n",
    "y_train = sess.run(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.constant(y_train, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w1 = tf.get_variable('w1',[784,100], initializer=tf.contrib.layers.xavier_initializer()) #deep-learning #xavier 초기화 해줌\n",
    "b1 = tf.get_variable('b1',[100], initializer=tf.contrib.layers.xavier_initializer())\n",
    "z1 = tf.matmul(x,w1) + b1 #(784,100)\n",
    "lay1 = tf.nn.softmax(z1)  #학습이 안되면 중간중간 RELu를 넣어주어야 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2 = tf.get_variable('w2',[100,10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.get_variable('b2',[10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "z2 = tf.matmul(lay1,w2) + b2 \n",
    "hx = tf.nn.softmax(z2) #맨 마지막에는 무조건 softmax가 와야한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_i = tf.nn.softmax_cross_entropy_with_logits_v2(logits=z2, labels=y)  #소프트맥스와 크로스앤트로피가 결합되어있는 것이다. \n",
    "\n",
    "cost = tf.reduce_mean(cost_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(0.1) #Learning rate\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_loss =[]\n",
    "patience = 16\n",
    "min_delta = 0.001 #이전값과 16번 비교하여 min_delta보다 작으면 빠져나가겠다. \n",
    "pcnt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.1852245\n",
      "1 2.2318177\n",
      "2 2.0877721\n",
      "3 2.024082\n",
      "4 1.9331435\n",
      "5 1.8849747\n",
      "6 1.8046188\n",
      "7 1.7479028\n",
      "8 1.6590172\n",
      "9 1.6186073\n",
      "10 1.5909549\n",
      "11 1.5267386\n",
      "12 1.4597325\n",
      "13 1.4333653\n",
      "14 1.3907522\n",
      "15 1.3620424\n",
      "16 1.3254943\n",
      "17 1.2880943\n",
      "18 1.2434162\n",
      "19 1.3396719\n",
      "20 1.2175239\n",
      "21 1.2156119\n",
      "22 1.2054018\n",
      "23 1.2390938\n",
      "24 1.3220477\n",
      "25 1.2827333\n",
      "26 1.2114106\n",
      "27 1.1737401\n",
      "28 1.1498218\n",
      "29 1.1540906\n",
      "30 1.1515305\n",
      "31 1.1526933\n",
      "32 1.1671318\n",
      "33 1.1842172\n",
      "34 1.1600788\n",
      "35 1.1879221\n",
      "36 1.1188792\n",
      "37 1.1130383\n",
      "38 1.1444037\n",
      "39 1.1752294\n",
      "40 1.170153\n",
      "41 1.1823202\n",
      "42 1.1579018\n",
      "43 1.124675\n",
      "44 1.0723238\n",
      "45 1.0672625\n",
      "46 1.08227\n",
      "47 1.1000633\n",
      "48 1.0903287\n",
      "49 1.0766163\n",
      "50 1.0482311\n",
      "51 1.0292138\n",
      "52 1.0163743\n",
      "53 1.015186\n",
      "54 1.0268973\n",
      "55 1.0482608\n",
      "56 1.0646523\n",
      "57 1.0446115\n",
      "58 1.0096371\n",
      "59 1.0019507\n",
      "60 1.0087874\n",
      "61 1.0392245\n",
      "62 1.0820241\n",
      "63 1.1734124\n",
      "64 1.2409472\n",
      "65 1.2288834\n",
      "66 1.1348401\n",
      "67 1.0567899\n",
      "68 1.0177451\n",
      "69 1.0088468\n",
      "70 1.0167854\n",
      "71 1.046126\n",
      "72 1.0694699\n",
      "73 1.0690582\n",
      "74 1.0250659\n",
      "75 0.99806195\n",
      "76 0.99226785\n",
      "77 1.0000187\n",
      "78 1.0087286\n",
      "79 1.0120103\n",
      "80 1.0015429\n",
      "81 0.9944163\n",
      "82 1.0078058\n",
      "83 1.0238676\n",
      "84 1.0333446\n",
      "85 1.0418222\n",
      "86 1.040854\n",
      "87 1.0220042\n",
      "88 0.9998472\n",
      "89 0.9894794\n",
      "90 0.97015005\n",
      "91 0.9623989\n",
      "92 0.96934474\n",
      "93 0.9737391\n",
      "94 0.97996116\n",
      "95 0.9924384\n",
      "96 0.9935407\n",
      "97 1.001247\n",
      "98 1.0121099\n",
      "99 1.008105\n",
      "100 0.98374146\n",
      "101 0.98290986\n",
      "102 1.0188884\n",
      "103 1.0408068\n",
      "104 1.016053\n",
      "105 0.970826\n",
      "106 0.94758546\n",
      "107 0.95156616\n",
      "108 0.95962596\n",
      "109 0.959728\n",
      "110 0.9586577\n",
      "111 0.9560883\n",
      "112 0.9469209\n",
      "113 0.94149584\n",
      "114 0.9423991\n",
      "115 0.9487331\n",
      "116 0.9562358\n",
      "117 0.9583625\n",
      "118 0.95801836\n",
      "119 0.9598293\n",
      "120 0.9670728\n",
      "121 0.97162837\n",
      "122 0.96388847\n",
      "123 0.9570882\n",
      "124 0.9591273\n",
      "125 0.9683181\n",
      "126 0.9842253\n",
      "127 0.99935514\n",
      "128 1.0074526\n",
      "129 1.0134751\n",
      "130 1.0228045\n",
      "131 0.9891638\n",
      "132 0.95713925\n",
      "133 0.9557336\n",
      "134 0.97600716\n",
      "135 1.0188149\n",
      "136 1.0840893\n",
      "137 1.1239185\n",
      "138 1.0857676\n",
      "139 1.0281829\n",
      "140 0.9914867\n",
      "141 0.97884744\n",
      "142 0.9805843\n",
      "143 0.9874974\n",
      "144 0.99774075\n",
      "145 1.0040996\n",
      "146 1.0096072\n",
      "147 1.0059935\n",
      "148 0.99710786\n",
      "149 0.99135923\n",
      "150 0.9875342\n",
      "151 0.9894299\n",
      "152 0.9976556\n",
      "153 1.0103679\n",
      "154 1.0240949\n",
      "155 1.0352288\n",
      "156 1.0321743\n",
      "157 1.0094258\n",
      "158 0.99367845\n",
      "159 0.9697505\n",
      "160 0.96326226\n",
      "161 0.9626324\n",
      "162 0.9702896\n",
      "163 0.9897085\n",
      "164 1.0038159\n",
      "165 1.0124416\n",
      "166 1.0218965\n",
      "167 1.0157772\n",
      "168 1.0062033\n",
      "169 0.9835988\n",
      "170 0.96923995\n",
      "171 0.9662743\n",
      "172 0.96051073\n",
      "173 0.9682781\n",
      "174 0.9708538\n",
      "175 0.9785387\n",
      "176 0.98686343\n",
      "177 0.96788096\n",
      "178 0.9495762\n",
      "179 0.93563855\n",
      "180 0.9349436\n",
      "181 0.94511276\n",
      "182 0.95905155\n",
      "183 0.9727305\n",
      "184 0.9782407\n",
      "185 0.97682714\n",
      "186 0.97121537\n",
      "187 0.9657518\n",
      "188 0.95791227\n",
      "189 0.9565418\n",
      "190 0.95185983\n",
      "191 0.9468455\n",
      "192 0.9450501\n",
      "193 0.94497967\n",
      "194 0.94246775\n",
      "195 0.94104075\n",
      "196 0.93614143\n",
      "197 0.9319744\n",
      "198 0.9272997\n",
      "199 0.923312\n",
      "200 0.91650647\n",
      "201 0.91032004\n",
      "202 0.90655184\n",
      "203 0.9056188\n",
      "204 0.906024\n",
      "205 0.9089242\n",
      "206 0.9104295\n",
      "207 0.91103256\n",
      "208 0.912668\n",
      "209 0.9133853\n",
      "210 0.9123232\n",
      "211 0.91144776\n",
      "212 0.9141455\n",
      "213 0.9178665\n",
      "214 0.9217076\n",
      "215 0.92143726\n",
      "216 0.91939366\n",
      "217 0.9176249\n",
      "218 0.9156784\n",
      "219 0.91420263\n",
      "220 0.914737\n",
      "221 0.91406417\n",
      "222 0.91152865\n",
      "223 0.9154489\n",
      "224 0.92929065\n",
      "225 0.940456\n",
      "226 0.95523924\n",
      "227 0.95123553\n",
      "228 0.95162225\n",
      "229 0.95419097\n",
      "230 0.94853574\n",
      "231 0.94328624\n",
      "232 0.9562322\n",
      "233 0.94776225\n",
      "234 0.9380736\n",
      "235 0.93170923\n",
      "236 0.92144537\n",
      "237 0.9118768\n",
      "238 0.9067491\n",
      "239 0.909845\n",
      "240 0.9159892\n",
      "241 0.93745613\n",
      "242 0.966059\n",
      "243 1.0131551\n",
      "244 1.004997\n",
      "245 1.0009172\n",
      "246 0.9926899\n",
      "247 0.9896915\n",
      "248 0.9943373\n",
      "249 1.0017881\n",
      "250 0.98809963\n",
      "251 0.9799974\n",
      "252 0.9669036\n",
      "253 0.9518379\n",
      "254 0.94293666\n",
      "255 0.93685484\n",
      "256 0.93661994\n",
      "257 0.9373309\n",
      "258 0.941375\n",
      "259 0.9485017\n",
      "260 0.96364427\n",
      "261 0.97834575\n",
      "262 0.9989376\n",
      "263 1.0171733\n",
      "264 0.98592174\n",
      "265 0.9767482\n",
      "266 0.9557188\n",
      "267 0.94672436\n",
      "268 0.9443281\n",
      "269 0.9454617\n",
      "270 0.94525576\n",
      "271 0.9444992\n",
      "272 0.94524324\n",
      "273 0.9442458\n",
      "274 0.9449935\n",
      "275 0.9475824\n",
      "276 0.95399064\n",
      "277 0.96992993\n",
      "278 0.9798293\n",
      "279 0.97817034\n",
      "280 0.9624483\n",
      "281 0.9489017\n",
      "282 0.95240414\n",
      "283 0.95292485\n",
      "284 0.95503396\n",
      "285 0.9566216\n",
      "286 0.9576025\n",
      "287 0.9574548\n",
      "288 0.95272154\n",
      "289 0.94491\n",
      "290 0.9408594\n",
      "291 0.9344036\n",
      "292 0.9342526\n",
      "293 0.9388272\n",
      "294 0.9373229\n",
      "295 0.93525344\n",
      "296 0.9343153\n",
      "297 0.9343895\n",
      "298 0.93603617\n",
      "299 0.94284177\n"
     ]
    }
   ],
   "source": [
    "for i in range(300):\n",
    "    sess.run(train,{x:x_train}) #벼림 연산 # w = w.assign(w-0.1*g)\n",
    "    c = sess.run(cost,{x:x_train}) \n",
    "    hist_loss.append( c )\n",
    "    print(i, c)\n",
    "    if i > 0 :\n",
    "        if hist_loss[i-1]-hist_loss[i] > min_delta:\n",
    "            pcnt = 0\n",
    "        else:\n",
    "            pcnt+= 1\n",
    "        if pcnt > patience:\n",
    "            print ('early stopping...')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   3,   1,   0,   0,   7,   0,  37,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          1,   2,   0,  27,  84,  11,   0,   0,   0,   0,   0,   0, 119,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          1,   0,   0,  88, 143, 110,   0,   0,   0,   0,  22,  93, 106,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          4,   0,  53, 129, 120, 147, 175, 157, 166, 135, 154, 168, 140,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   2,\n",
       "          0,  11, 137, 130, 128, 160, 176, 159, 167, 178, 149, 151, 144,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   1,   0,   2,   1,   0,   3,   0,\n",
       "          0, 115, 114, 106, 137, 168, 153, 156, 165, 167, 143, 157, 158,\n",
       "         11,   0],\n",
       "       [  0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   3,   0,   0,\n",
       "         89, 139,  90,  94, 153, 149, 131, 151, 169, 172, 143, 159, 169,\n",
       "         48,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   2,   4,   1,   0,   0,   0,  98,\n",
       "        136, 110, 109, 110, 162, 135, 144, 149, 159, 167, 144, 158, 169,\n",
       "        119,   0],\n",
       "       [  0,   0,   2,   2,   1,   2,   0,   0,   0,   0,  26, 108, 117,\n",
       "         99, 111, 117, 136, 156, 134, 154, 154, 156, 160, 141, 147, 156,\n",
       "        178,   0],\n",
       "       [  3,   0,   0,   0,   0,   0,   0,  21,  53,  92, 117, 111, 103,\n",
       "        115, 129, 134, 143, 154, 165, 170, 154, 151, 154, 143, 138, 150,\n",
       "        165,  43],\n",
       "       [  0,   0,  23,  54,  65,  76,  85, 118, 128, 123, 111, 113, 118,\n",
       "        127, 125, 139, 133, 136, 160, 140, 155, 161, 144, 155, 172, 161,\n",
       "        189,  62],\n",
       "       [  0,  68,  94,  90, 111, 114, 111, 114, 115, 127, 135, 136, 143,\n",
       "        126, 127, 151, 154, 143, 148, 125, 162, 162, 144, 138, 153, 162,\n",
       "        196,  58],\n",
       "       [ 70, 169, 129, 104,  98, 100,  94,  97,  98, 102, 108, 106, 119,\n",
       "        120, 129, 149, 156, 167, 190, 190, 196, 198, 198, 187, 197, 189,\n",
       "        184,  36],\n",
       "       [ 16, 126, 171, 188, 188, 184, 171, 153, 135, 120, 126, 127, 146,\n",
       "        185, 195, 209, 208, 255, 209, 177, 245, 252, 251, 251, 247, 220,\n",
       "        206,  49],\n",
       "       [  0,   0,   0,  12,  67, 106, 164, 185, 199, 210, 211, 210, 208,\n",
       "        190, 150,  82,   8,   0,   0,   0, 178, 208, 188, 175, 162, 158,\n",
       "        151,  11],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0].reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.81628842e-04, 2.62877555e-04, 4.11347515e-04, ...,\n",
       "        5.89050353e-02, 4.36485093e-03, 6.30991340e-01],\n",
       "       [5.05447807e-03, 1.22976257e-03, 4.29568380e-01, ...,\n",
       "        2.74190970e-04, 3.59331537e-03, 3.16893827e-04],\n",
       "       [5.94827458e-02, 4.16365176e-01, 1.11607835e-02, ...,\n",
       "        6.27535512e-04, 4.32543410e-03, 9.45011736e-04],\n",
       "       ...,\n",
       "       [5.85853495e-03, 1.43783327e-04, 3.74770514e-03, ...,\n",
       "        2.77421321e-03, 9.71427441e-01, 6.61256607e-04],\n",
       "       [5.94827458e-02, 4.16365176e-01, 1.11607835e-02, ...,\n",
       "        6.27535512e-04, 4.32543410e-03, 9.45011736e-04],\n",
       "       [2.64559494e-04, 6.39826249e-05, 3.09588533e-04, ...,\n",
       "        3.70120890e-02, 6.15083752e-03, 8.69770069e-03]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1 = sess.run(hx, {x:x_test})\n",
    "h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 3, ..., 8, 3, 5], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2 = h1.argmax(axis = 1)\n",
    "h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5864"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_test==h2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[0].reshape(28,28))\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.8162884e-04, 2.6287755e-04, 4.1134752e-04, 2.7286235e-04,\n",
       "        2.8213876e-04, 3.0348518e-01, 5.4275384e-04, 5.8905035e-02,\n",
       "        4.3648509e-03, 6.3099134e-01]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(hx, {x:x_test[[0]]}) #7이라는 이미지를 주었을 때 예측값이 얼마인가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(hx, {x:x_test[[0]]}).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5864"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(h2,y_test), dtype=tf.float32))\n",
    "sess.run(accuracy,{x:x_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
