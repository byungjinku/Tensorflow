{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder( tf.float32 )\n",
    "y = tf.constant( [1,2,3], tf.float32)\n",
    "# w = tf.Variable( 10.0)\n",
    "# b = tf.Variable( 10.0)\n",
    "w = tf.get_variable('w1', shape=[1],\n",
    "        initializer=tf.contrib.layers.xavier_initializer() )\n",
    "b = tf.get_variable('b1', shape=[1],\n",
    "        initializer=tf.contrib.layers.xavier_initializer() )\n",
    "# xavier, he algorithm (초기화 알고리즘)\n",
    "# tf.contrib.layers.variance_scaling_initializer() (he)\n",
    "hx = w*x + b\n",
    "cost = tf.reduce_mean( tf.square(hx-y) )\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.1)#learning rate\n",
    "train = optimizer.minimize( cost )\n",
    "sess = tf.Session()\n",
    "init =tf.global_variables_initializer()\n",
    "sess.run( init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.3639541\n",
      "1 0.34520122\n",
      "2 0.3287864\n",
      "3 0.31316864\n",
      "4 0.2982929\n",
      "5 0.28412378\n",
      "6 0.27062768\n",
      "7 0.25777268\n",
      "8 0.24552828\n",
      "9 0.23386557\n",
      "10 0.22275676\n",
      "11 0.21217567\n",
      "12 0.20209712\n",
      "13 0.19249737\n",
      "14 0.18335362\n",
      "15 0.17464416\n",
      "16 0.16634844\n",
      "17 0.15844677\n",
      "18 0.1509204\n",
      "19 0.14375158\n",
      "20 0.13692325\n",
      "21 0.13041934\n",
      "22 0.124224335\n",
      "23 0.118323565\n",
      "24 0.112703115\n",
      "25 0.10734963\n",
      "26 0.102250434\n",
      "27 0.09739346\n",
      "28 0.0927672\n",
      "29 0.0883607\n",
      "30 0.08416349\n",
      "31 0.08016571\n",
      "32 0.0763577\n",
      "33 0.07273071\n",
      "34 0.06927592\n",
      "35 0.06598528\n",
      "36 0.062850915\n",
      "37 0.059865434\n",
      "38 0.057021815\n",
      "39 0.054313216\n",
      "40 0.05173329\n",
      "41 0.04927594\n",
      "42 0.046935305\n",
      "43 0.044705838\n",
      "44 0.042582285\n",
      "45 0.040559594\n",
      "46 0.038632955\n",
      "47 0.036797892\n",
      "48 0.035049956\n",
      "49 0.033385072\n",
      "50 0.03179924\n",
      "51 0.030288758\n",
      "52 0.028850006\n",
      "53 0.027479641\n",
      "54 0.026174316\n",
      "55 0.024931036\n",
      "56 0.023746775\n",
      "57 0.022618793\n",
      "58 0.021544375\n",
      "59 0.020521002\n",
      "60 0.019546235\n",
      "61 0.018617788\n",
      "62 0.017733427\n",
      "63 0.01689106\n",
      "64 0.016088726\n",
      "65 0.015324515\n",
      "66 0.014596585\n",
      "67 0.013903252\n",
      "68 0.013242826\n",
      "69 0.012613766\n",
      "70 0.012014623\n",
      "71 0.01144392\n",
      "72 0.010900315\n",
      "73 0.010382536\n",
      "74 0.009889373\n",
      "75 0.00941962\n",
      "76 0.008972182\n",
      "early stopping...\n"
     ]
    }
   ],
   "source": [
    "hist_loss=[]\n",
    "patience = 16\n",
    "min_delta = 0.001\n",
    "for i in range(300):\n",
    "    sess.run(train,{x:[1,2,3]})\n",
    "    c = sess.run(cost,{x:[1,2,3]} )\n",
    "    hist_loss.append( c )\n",
    "    print(i, c )\n",
    "    if i>0:\n",
    "        if hist_loss[i-1]-hist_loss[i]>min_delta:\n",
    "            pcnt=0\n",
    "        else:\n",
    "            pcnt+=1\n",
    "        if pcnt>patience:\n",
    "            print(\"early stopping...\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 충분히\n",
    "- 이전데이터랑 비교해 일정값 이상 변화가 없으면 break 로 반복문종료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1,2,3]\n",
    "y = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3 samples\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 18ms/sample - loss: 19.9675\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 17.3061\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 4ms/sample - loss: 14.8442\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 12.5845\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 745us/sample - loss: 10.5289\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 667us/sample - loss: 8.6781\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 625us/sample - loss: 7.0312\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 665us/sample - loss: 5.5861\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 520us/sample - loss: 4.3384\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 3.2821\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 2.4091\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 1.7089\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 398us/sample - loss: 1.1689\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 0.7746\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.5094\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.3552\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.2931\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 0.3034\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 255us/sample - loss: 0.3669\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 476us/sample - loss: 0.4653\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 0.5820\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.7023\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.8144\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 332us/sample - loss: 0.9091\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 669us/sample - loss: 0.9802\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 330us/sample - loss: 1.0242\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 666us/sample - loss: 1.0400\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 1.0289\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 330us/sample - loss: 0.9936\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.9381\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.8672\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 335us/sample - loss: 0.7860\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 337us/sample - loss: 0.6995\n"
     ]
    }
   ],
   "source": [
    "IO = Dense(units=1, input_dim=1)\n",
    "model = Sequential( [IO])\n",
    "model.compile(loss=\"mean_squared_error\",optimizer=Adam(0.1))\n",
    "early = EarlyStopping(monitor='loss',min_delta=0.001,\n",
    "                      patience=16)\n",
    "h = model.fit( x,y,epochs=1000, callbacks=[early] )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
