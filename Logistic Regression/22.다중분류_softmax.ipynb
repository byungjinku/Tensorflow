{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다중분류 시에 쓰임. 원래 sigmoid는 0 아니면 1로 분류된다. \n",
    "#### 다중분류는 이진분류를 n번 시행하는 것이다.\n",
    "(만약 3개로 분류하고 싶으면 이진분류를 3번 수행하게 된다. 100,010,001)\n",
    "\n",
    "W(weight) 행렬= [피쳐의 개수, 분류의 개수]\n",
    "\n",
    "WX(예측값)를 시그모이드를 통과시키지 않고 확률로 변환해준다. \n",
    "\n",
    "bias의 개수는 분류의 개수만큼 나온다\n",
    "\n",
    "올바른 예측을 하면 COST 값이 작게 나오고, 잘못된 예측을 하면 COST값이 크게 나온다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn(x):\n",
    "    return x/x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    e = np.exp(x) #[e^2.0, e^1.0, e^0.1] #값이 더 큰쪽에 확률을 높게주고, 값이 작은 쪽에 확률을 낮게 주기 위해 지수함수를 가져오는것임\n",
    "    print('e=',e)\n",
    "    print(e/np.sum(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e= [7.3890561  2.71828183 1.10517092]\n",
      "[0.65900114 0.24243297 0.09856589]\n"
     ]
    }
   ],
   "source": [
    "a = np.array( [2.0,1.0,0.1] ) # 각 요소/전체 합 (확률로 나타낸 것이다)\n",
    "# fn(a)\n",
    "softmax(a) #약 p = [0.7, 0.2, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
